{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea2ce8-b5b4-49eb-9bf4-80bc1a8d86e0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c0411-843e-4539-9454-4330901e92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff2(f, X):\n",
    "  DX = 1e-4\n",
    "  grad_grad = []\n",
    "  for i in range(X.shape[1]):\n",
    "    delta_X = torch.zeros_like(X)\n",
    "    delta_X[:,i] = DX\n",
    "    df2 = (f(X+delta_X) - 2*f(X) + f(X-delta_X)) / DX**2\n",
    "    grad_grad.append(df2)\n",
    "  return torch.stack(grad_grad, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da89454-1df7-4e7b-b7f0-cfeff8518206",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class diff_model_enable:\n",
    "#   def __init__(self, model, X):\n",
    "#     self.model = model\n",
    "#     self.X = X\n",
    "  \n",
    "#   def __enter__(self):\n",
    "#     self.X.requires_grad = True\n",
    "  \n",
    "#   def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "#     self.X.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47c411-4b5e-4b6f-aadf-4830be4c22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def diff2(f, X):\n",
    "#   grads = torch.autograd.grad(\n",
    "#     outputs=f, inputs=X, grad_outputs=torch.ones_like(f),\n",
    "#     create_graph=True\n",
    "#   )[0]\n",
    "#   grad_grad = []\n",
    "#   for i in range(X.shape[1]):\n",
    "#     df = grads[:,i]\n",
    "#     df2 = torch.autograd.grad(\n",
    "#       outputs=df, inputs=X, grad_outputs=torch.ones_like(df),\n",
    "#       create_graph=True\n",
    "#     )[0][:,i]\n",
    "#     grad_grad.append(df2)\n",
    "#   return torch.stack(grad_grad, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61039a1c-3907-4d3d-9444-1b5dfe9265be",
   "metadata": {
    "id": "0bcd14a8-54ee-49f4-b28f-cc854569cae2"
   },
   "source": [
    "# Metropolis sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1990a-4713-4aae-a65d-5abe6cc1681e",
   "metadata": {
    "id": "db80e74d-bb8f-4a88-bd6d-d65e2a0c1ac5"
   },
   "outputs": [],
   "source": [
    "class MetropolisSampler():\n",
    "  \"\"\"Class for Metropolis sampler\"\"\"\n",
    "\n",
    "  def __init__(self, dim1, dim2, epsilon=0.1, device='cpu'):\n",
    "    self.epsilon = epsilon\n",
    "    self.device = device\n",
    "    self.sample = self.initialSample(dim1, dim2)\n",
    "\n",
    "  def initialSample(self, dim1, dim2) -> torch.Tensor:\n",
    "    return 3 * (\n",
    "      torch.rand(\n",
    "        (\n",
    "          dim1, dim2\n",
    "        )\n",
    "      ) - 0.5\n",
    "    ).to(self.device)\n",
    "\n",
    "  def updateSampleBasOnDistrDens(self, __distributionDensity):\n",
    "    newSample = self.sample + self.epsilon * (\n",
    "      2 * torch.rand_like(\n",
    "        self.sample,\n",
    "        device=self.device\n",
    "      ) - 1\n",
    "    )\n",
    "    critVal = __distributionDensity(newSample) / __distributionDensity(self.sample)\n",
    "    doesPointMove = (torch.rand(len(self.sample), device=self.device) <= critVal)\n",
    "    newSample = (\n",
    "      torch.mul(doesPointMove.int(), newSample.t()).t()\n",
    "      + torch.mul((1 - doesPointMove.int()), self.sample.t()).t()\n",
    "    )\n",
    "    self.sample = newSample\n",
    "\n",
    "  def updateAndGetSample(self, __distributionDensity):\n",
    "    for i in range(10):\n",
    "      self.updateSampleBasOnDistrDens(__distributionDensity)\n",
    "    return self.sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e20ee-4d33-45d6-8811-9613f84a61cc",
   "metadata": {},
   "source": [
    "# Integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330e900-f04c-4be8-a86d-5753cd2a3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(f, density) -> torch.Tensor:\n",
    "  return torch.mean(f / density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63011a7e-3d7e-4ac0-8f8e-6ba94d6b3f77",
   "metadata": {},
   "source": [
    "# Trial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d4dc9-3857-41b2-84c0-ec86234bc625",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrialFunction(nn.Module):\n",
    "  def __init__(self, dim_coord, num_states, potential, name,\n",
    "               num_hidden_layers=3, num_hidden_neurons=60,\n",
    "               init_mean_weights=0.0, init_std_weights=math.sqrt(0.1),\n",
    "               activ_fnc=nn.Sigmoid()):\n",
    "    super(TrialFunction, self).__init__()\n",
    "    \n",
    "    self.dim_coord = dim_coord\n",
    "    self.num_states = num_states\n",
    "    self.potential = potential\n",
    "\n",
    "    self.name = name\n",
    "    \n",
    "    self.num_hidden_layers = num_hidden_layers\n",
    "    self.num_hidden_neurons = num_hidden_neurons\n",
    "    self.activ_fnc = activ_fnc\n",
    "    # Layers\n",
    "    self.layers = nn.Sequential()\n",
    "    self.layers.append(nn.Linear(dim_coord, num_hidden_neurons))\n",
    "    self.layers.append(activ_fnc)\n",
    "    for layer in range(num_hidden_layers-1):\n",
    "      self.layers.append(nn.Linear(num_hidden_neurons, num_hidden_neurons))\n",
    "      self.layers.append(activ_fnc)\n",
    "    # Gaussian weights\n",
    "    self.gaussian_weights= nn.Linear(dim_coord, num_hidden_neurons, bias=False)\n",
    "    # Out layer\n",
    "    self.out_layer = nn.ModuleList(\n",
    "      [nn.Linear(num_hidden_neurons, 1, bias=False) for state in range(num_states)]\n",
    "    )\n",
    "    # Initialise weigths\n",
    "    self.init_weights(init_mean_weights, init_std_weights)\n",
    "\n",
    "  def init_weights(self, init_mean_weights, init_std_weights):\n",
    "    for layer in range(len(self.layers)):\n",
    "      if 'weight' in dir(self.layers[layer]):\n",
    "        nn.init.normal_(self.layers[layer].weight, init_mean_weights, init_std_weights)\n",
    "      if 'bias' in dir(self.layers[layer]):\n",
    "        nn.init.normal_(self.layers[layer].bias, init_mean_weights, init_std_weights)\n",
    "\n",
    "    for layer in range(len(self.out_layer)):\n",
    "      if 'weight' in dir(self.out_layer[layer]):\n",
    "        nn.init.normal_(\n",
    "          self.out_layer[layer].weight, \n",
    "          init_mean_weights,  #1.0/math.sqrt(self.num_hidden_neurons), \n",
    "          init_std_weights\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = self.layers(x)\n",
    "    \n",
    "    sqr_gauss_weights = self.gaussian_weights.weight*self.gaussian_weights.weight\n",
    "    gauss_kernel = torch.exp(-torch.matmul(x*x, torch.transpose(sqr_gauss_weights, 0, 1)))\n",
    "\n",
    "    z_prime = gauss_kernel * z\n",
    "    return torch.stack([psi_n(z_prime)for psi_n in self.out_layer], dim=1).squeeze(2)\n",
    "\n",
    "  def weigth_function(self, x):\n",
    "    forward_ = self.forward(x)\n",
    "    return torch.mean(forward_**2 / torch.max(forward_**2, dim=0)[0], dim=1).detach()\n",
    "  \n",
    "  def laplacian(self, x):\n",
    "    DX = 1e-4\n",
    "    grad_grad = []\n",
    "    for i in range(self.dim_coord):\n",
    "      delta_x = torch.zeros_like(x)\n",
    "      delta_x[:,i] = DX\n",
    "      df2 = (self.forward(x+delta_x) - 2 * self.forward(x) + self.forward(x-delta_x)) / DX**2\n",
    "      grad_grad += [df2]\n",
    "    return sum(grad_grad)\n",
    "\n",
    "  def hamiltonian(self, x):\n",
    "    return (\n",
    "      -0.5 * self.laplacian(x)\n",
    "      + self.potential(x).unsqueeze(1) * self.forward(x)\n",
    "    )\n",
    "\n",
    "  def rayleigh(self, x):\n",
    "    weigth_function_ = self.weigth_function(x)\n",
    "    forward_ = self.forward(x)\n",
    "    hamiltonian_ = self.hamiltonian(x)\n",
    "    return [\n",
    "      integrate(forward_[:,s]*hamiltonian_[:,s], weigth_function_)\n",
    "      / integrate(forward_[:,s]*forward_[:,s], weigth_function_) for s in range(self.num_states)]\n",
    "\n",
    "  def sqr_res_per_state(self, x):\n",
    "    rayleigh_ = self.rayleigh(x)\n",
    "    weigth_function_ = self.weigth_function(x)\n",
    "    forward_ = self.forward(x)\n",
    "    hamiltonian_ = self.hamiltonian(x)\n",
    "    return [\n",
    "      integrate((hamiltonian_[:,s] - rayleigh_[s] * forward_[:,s])**2, weigth_function_)\n",
    "      / integrate(forward_[:,s]*forward_[:,s], weigth_function_) for s in range(self.num_states)]\n",
    "\n",
    "  def sqr_res(self, x):\n",
    "    return sum(self.sqr_res_per_state(x))\n",
    "\n",
    "  # def norm_cond(self, x):\n",
    "  #   result = []\n",
    "  #   weigth_function_ = self.weigth_function(x)\n",
    "  #   forward_ = self.forward(x)\n",
    "  #   for s in range(self.num_states):\n",
    "  #     result += [(integrate(forward_[:,s]**2, weigth_function_) - 1)**2]\n",
    "  #   return sum(result)\n",
    "  \n",
    "  def norm_cond(self):\n",
    "    return sum((torch.sum(A*A, dim=1) - 1)**2 for A in self.out_layer.parameters())\n",
    "\n",
    "  def orthogon_cond(self, x):\n",
    "    result = []\n",
    "    weigth_function_ = self.weigth_function(x)\n",
    "    forward_ = self.forward(x)\n",
    "    for s1, s2 in combinations(list(range(self.num_states)), 2):\n",
    "      result += [\n",
    "        torch.square(integrate(forward_[:,s1]*forward_[:,s2], weigth_function_)) \n",
    "        / integrate(forward_[:,s1]*forward_[:,s1], weigth_function_) \n",
    "        / integrate(forward_[:,s2]*forward_[:,s2], weigth_function_)\n",
    "      ]\n",
    "    return sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337074a-9614-4e89-a665-1657e30a5fa9",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b3437-8c39-43f0-854c-2457cae5df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, step, loss):\n",
    "  checkpoint = {\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    'step' : step,\n",
    "    'loss' : loss\n",
    "  }\n",
    "  fn = f\"checkpoints/{model.name}.pt\"\n",
    "  torch.save(checkpoint, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2062b4e2-468e-426a-88e7-fe002a25d2b6",
   "metadata": {},
   "source": [
    "# Test (He)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b6496-e88e-4a1d-bd8f-a58a517891df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_coord = 6\n",
    "num_states = 5\n",
    "potential = lambda x: (\n",
    "  -2/torch.sqrt(torch.sum(x[:,:3]**2, dim=1))\n",
    "  -2/torch.sqrt(torch.sum(x[:,3:]**2, dim=1))\n",
    "  +1/torch.sqrt(torch.sum((x[:,:3]-x[:,3:])**2, dim=1))\n",
    ")\n",
    "num_hidden_layers = 3\n",
    "num_hidden_neurons = 60\n",
    "init_mean_weights = 0.0\n",
    "init_std_weights = math.sqrt(0.1)\n",
    "activ_fnc = nn.Tanh()\n",
    "\n",
    "alpha = 2\n",
    "beta = 1\n",
    "gamma = 40\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "S = 8000\n",
    "sampler = MetropolisSampler(dim1=S, dim2=dim_coord, epsilon=0.1, device=device)\n",
    "\n",
    "lr = 1e-2\n",
    "weight_decay = 5e-4\n",
    "\n",
    "CHECKPOINT_PERIOD = 10\n",
    "\n",
    "MAX_SQR_RESIDUAL = 1e-3\n",
    "\n",
    "load_checkpoint = False\n",
    "\n",
    "name = \"test_He\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff09a80-b701-4dd1-bd26-727139451344",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = time.time()\n",
    "  \n",
    "hist = {\n",
    "  'time' : list(),\n",
    "  'loss' : list(),\n",
    "  'sqr res' : list(),\n",
    "  'norm cond' : list(),\n",
    "  'orthogon cond' : list(),\n",
    "}\n",
    "for state in range(num_states):\n",
    "  hist[f\"Rayleigh{state}\"] = list()\n",
    "\n",
    "model = TrialFunction(dim_coord, num_states, potential, name,\n",
    "               num_hidden_layers, num_hidden_neurons,\n",
    "               init_mean_weights, init_std_weights,\n",
    "               activ_fnc).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "  params=list(model.parameters()),\n",
    "  lr=lr,\n",
    "  weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "if load_checkpoint:\n",
    "  checkpoint = torch.load(f\"checkpoints/{model.name}.pt\")\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  model.train()\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  step = checkpoint['step']\n",
    "  loss = checkpoint['loss']\n",
    "  print(f\"Load model and optimizer: step {checkpoint['step']}, loss {checkpoint['loss']}\")\n",
    "  # history\n",
    "  hist_df = pd.read_csv(f\"history/{model.name}.csv\")\n",
    "  hist['time'] = hist_df['time'].to_list()\n",
    "  hist['loss'] = hist_df['loss'].to_list()\n",
    "  hist['sqr res'] = hist_df['sqr res'].to_list()\n",
    "  hist['norm cond'] = hist_df['norm cond'].to_list()\n",
    "  hist['orthogon cond'] = hist_df['orthogon cond'].to_list()\n",
    "  for state in range(num_states):\n",
    "    hist[f\"Rayleigh{state}\"] = hist_df[f\"Rayleigh{state}\"].to_list()\n",
    "\n",
    "x = sampler.updateAndGetSample(model.weigth_function)\n",
    "step = 0\n",
    "\n",
    "valid_states = 0\n",
    "while (valid_states < num_states):\n",
    "  step += 1\n",
    "  x = sampler.updateAndGetSample(model.weigth_function)\n",
    "\n",
    "  sqr_residual = model.sqr_res(x)\n",
    "\n",
    "  energies = model.rayleigh(x)\n",
    "\n",
    "  energ_cond = alpha * sum(energies)\n",
    "    \n",
    "  norm_cond = beta * model.norm_cond()\n",
    "   \n",
    "  orthogon_cond = gamma * model.orthogon_cond(x)\n",
    "\n",
    "  loss = (\n",
    "    sqr_residual \n",
    "    + energ_cond \n",
    "    + norm_cond \n",
    "    + orthogon_cond\n",
    "  )\n",
    "\n",
    "  sqr_res_per_state_ = torch.stack(model.sqr_res_per_state(x),dim=0).detach().cpu()\n",
    "  valid_states = sum((sqr_res_per_state_ < MAX_SQR_RESIDUAL))\n",
    "  \n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  hist['time'] += [time.time() - START_TIME]\n",
    "  hist['loss'] += [loss.item()]\n",
    "  hist['sqr res'] += [sqr_residual.item()]\n",
    "  hist['norm cond'] += [norm_cond.item()]\n",
    "  hist['orthogon cond'] += [orthogon_cond.item()]\n",
    "  for state in range(num_states):\n",
    "    hist[f\"Rayleigh{state}\"] += [energies[state].item()]\n",
    "\n",
    "  if step == 1:\n",
    "    header = (\n",
    "        \"step, time, loss, sqr res,\"\n",
    "        + \" norm cond, orthogon cond,\"\n",
    "    )\n",
    "    for i in range(num_states):\n",
    "      header += f\", Rayleigh{i}\"\n",
    "    header += \",\"\n",
    "    for i in range(num_states):\n",
    "      header += f\", sqr_res{i}\"\n",
    "    print(header)\n",
    "  \n",
    "  if (step % CHECKPOINT_PERIOD) == 0 or step == 1:            \n",
    "    info = (\n",
    "      f\"{step}, \"\n",
    "      + f\"{time.time() - START_TIME:.2f}, \"\n",
    "      + f\"{loss.item():.2e}, \"\n",
    "      + f\"{sqr_residual.item():.2e}, \"\n",
    "      + f\"{norm_cond.item():.2e}, \"\n",
    "      + f\"{orthogon_cond.item():.2e},\"\n",
    "    )\n",
    "    for Rayleigh_ in energies:\n",
    "      info += f\", {Rayleigh_.item():.2e}\"\n",
    "    info += \",\"\n",
    "    for i in range(num_states):\n",
    "      info += f\", {sqr_res_per_state_[i]:.2e}\"\n",
    "    print(info)\n",
    "      \n",
    "    hist_df = pd.DataFrame(data=hist)\n",
    "    hist_df.to_csv(f\"history/{model.name}.csv\")\n",
    "\n",
    "    save_checkpoint(model, optimizer, step, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33958f13-6a40-4a55-bfb3-d9de9f8a201f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc3a69-3556-4b04-a815-d554f48588ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a61a7-f2f3-4cbe-a07e-350cddfd89ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae414421-9efe-458b-813c-09c34aea5edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f078f92-ac8f-4271-892d-b174e4b9bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# hist = pd.read_csv(\"history/test_He.csv\")\n",
    "# xmax = len(hist)\n",
    "# xmin = 0 #xmax - 1000\n",
    "\n",
    "# fig, ax = plt.subplots(2,1,figsize=(16,7))\n",
    "\n",
    "# hist[['sqr res', 'norm cond',\n",
    "#        'orthogon cond']][xmin:xmax].plot(xlim=(xmin, xmax), ax = ax[0])\n",
    "# # ax[0].plot(np.arange(xmin,xmax), np.sum(hist[[f'Rayleigh{i}' for i in range(16)]][xmin:xmax].to_numpy(), axis=1))\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[0].grid(axis='y')\n",
    "\n",
    "# hist[[f'Rayleigh{i}' for i in range(16)]][xmin:xmax].plot(xlim=(xmin, xmax), legend=False, ax = ax[1], alpha=0.7)\n",
    "# ax[1].axhline(y=0, color='k', linestyle='--')\n",
    "# ax[1].grid(axis='y')\n",
    "# # ax[1].set_yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f699a-9553-42dd-bf7c-15429e2f914a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2498c0-183f-41c7-977e-9bf500fde3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
